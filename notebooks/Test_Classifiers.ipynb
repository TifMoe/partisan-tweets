{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Classifiers using advanced NLP techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import operator\n",
    "% matplotlib inline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from collections import defaultdict\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/processed/tokenized_test_b.pickle', 'rb') as file:\n",
    "    tokenized_test = pickle.load(file)\n",
    "with open('../data/processed/y_test_b.pickle', 'rb') as file:\n",
    "    test_y = pickle.load(file)\n",
    "    \n",
    "with open('../data/processed/tokenized_train_a.pickle', 'rb') as file:\n",
    "    tokenized_train = pickle.load(file)\n",
    "with open('../data/processed/y_train_a.pickle', 'rb') as file:\n",
    "    train_y = pickle.load(file)\n",
    "\n",
    "\n",
    "with open('../data/processed/w2v_dict.pickle', 'rb') as file:\n",
    "    w2v = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a confusion matrix plot\n",
    "def plot_confusion_matrix(cm, title='Confusion Matrix', cmap=plt.cm.Greys):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_auc(y_test, y_score):\n",
    "    \n",
    "    fpr, tpr, _ = roc_curve(y_test, y_score)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    plt.figure(figsize=(6, 6))\n",
    "\n",
    "    plt.plot([0,1],[0,1], linestyle=\":\", color='grey', linewidth=4) # this is our baseline\n",
    "    plt.plot(fpr, tpr, color='purple', alpha=.7, linewidth=3, label=\"AUC=\"+str(round(roc_auc, 3))) # this is our ROC curve\n",
    "    \n",
    "    plt.xlabel('FPR', fontsize=20)\n",
    "    plt.ylabel('TPR', fontsize=20)\n",
    "    plt.legend(loc=0)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    print('AUC: ', roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_classifier(features, target, seed, k_folds, crossval_scoring, models_list):\n",
    "\n",
    "    \"\"\"\n",
    "    Test multiple classifiers using cross validation.\n",
    "    Evaluate performance to find model with highest score as defined by the 'crossval_scoring' argument \n",
    "    ('roc_auc', 'f1', log_loss', precision', 'recall', etc)\n",
    "    \"\"\"\n",
    "\n",
    "    # Test options and evaluation metric\n",
    "    scoring=crossval_scoring\n",
    "\n",
    "    # Spot Check Algorithms\n",
    "    models = models_list\n",
    "\n",
    "    # Evaluate each model in turn\n",
    "    results = []\n",
    "    names = []\n",
    "\n",
    "    for name, model in models:\n",
    "        kfold = StratifiedKFold(n_splits=k_folds, random_state=seed)\n",
    "        cv_results = cross_val_score(model, features, target, cv=kfold, scoring=scoring)\n",
    "        results.append(cv_results)\n",
    "        names.append(name)\n",
    "        msg = \"%s: %s (%f), std (%f)\" % (name, scoring, cv_results.mean(), cv_results.std())\n",
    "        print(msg)\n",
    "\n",
    "    zipped_eval = zip(models, [i.mean() for i in results])\n",
    "    model_eval = sorted(zipped_eval, key=operator.itemgetter(1))\n",
    "    \n",
    "    best_clf = model_eval[-1][0][1]\n",
    "    clf_name = model_eval[-1][0][0]\n",
    "    print(\"\\n Model with best {} is {}\".format(scoring, clf_name))\n",
    "    print('\\n', best_clf)\n",
    "        \n",
    "    return best_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeanEmbeddingVectorizer(object):\n",
    "    def __init__(self, word2vec):\n",
    "        self.word2vec = word2vec\n",
    "        # if a text is empty we should return a vector of zeros\n",
    "        # with the same dimensionality as all the other vectors\n",
    "        self.dim = len(word2vec.values())\n",
    "\n",
    "    def fit(self, X):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return [\n",
    "            np.mean([self.word2vec[w] for w in words if w in self.word2vec]\n",
    "                    or [np.zeros(self.dim)], axis=0)\n",
    "            for words in X\n",
    "        ]\n",
    "\n",
    "\n",
    "class TfidfEmbeddingVectorizer(object):\n",
    "    def __init__(self, word2vec):\n",
    "        self.word2vec = word2vec\n",
    "        self.word2weight = None\n",
    "        self.dim = len(word2vec.items())\n",
    "\n",
    "    def fit(self, X):\n",
    "        tfidf = TfidfVectorizer(analyzer=lambda x: x)\n",
    "        tfidf.fit(X)\n",
    "        # if a word was never seen - it must be at least as infrequent\n",
    "        # as any of the known words - so the default idf is the max of\n",
    "        # known idf's\n",
    "        max_idf = max(tfidf.idf_)\n",
    "        self.word2weight = defaultdict(\n",
    "            lambda: max_idf,\n",
    "            [(w, tfidf.idf_[i]) for w, i in tfidf.vocabulary_.items()])\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return [\n",
    "                np.mean([self.word2vec[w] * self.word2weight[w]\n",
    "                         for w in words if w in self.word2vec] or\n",
    "                        [np.zeros(self.dim)], axis=0)\n",
    "                for words in X\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_features(vectorizer, list_tokens, set_dim=None):\n",
    "    \"\"\"\n",
    "    Utility function to generate word vectors for tweets\n",
    "    \"\"\"\n",
    "    vectorizer_ = vectorizer\n",
    "\n",
    "    if set_dim:\n",
    "        # Convert list of embeddings to dataframe and reshape relevant dimensions into multi-dimensional array\n",
    "        embeddings = vectorizer_.fit(list_tokens).transform(list_tokens)\n",
    "        df_tokens = pd.DataFrame(embeddings)\n",
    "        relevant = df.iloc[:, 0:set_dim]\n",
    "        features = np.array(relevant)\n",
    "        \n",
    "    else:\n",
    "        features = vectorizer_.fit(list_tokens).transform(list_tokens).toarray()\n",
    "    \n",
    "    return features\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test models with Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = generate_features(CountVectorizer(analyzer=lambda x: x), tokenized_test)\n",
    "\n",
    "models = [('NaiveBayesGaussian', GaussianNB()),\n",
    "          ('NaiveBayesBernoulli', BernoulliNB()),\n",
    "          ('NaiveBayesMultinomial', MultinomialNB()),\n",
    "          ('RandomForest', RandomForestClassifier(random_state=seed)),\n",
    "          ('ExtraTrees', ExtraTreesClassifier(random_state=seed))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_clf = find_best_classifier(features=features, \n",
    "                                target=test_y, \n",
    "                                seed=42, \n",
    "                                k_folds=5, \n",
    "                                crossval_scoring='roc_auc', \n",
    "                                models_list = models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test models with Tf-IDF Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = generate_features(TfidfVectorizer(analyzer=lambda x: x), tokenized_test)\n",
    "\n",
    "models = [('NaiveBayesGaussian', GaussianNB()),\n",
    "          ('NaiveBayesBernoulli', BernoulliNB()),\n",
    "          ('NaiveBayesMultinomial', MultinomialNB()),\n",
    "          ('RandomForest', RandomForestClassifier(random_state=seed)),\n",
    "          ('ExtraTrees', ExtraTreesClassifier(random_state=seed))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaiveBayesGaussian: roc_auc (0.661248), std (0.012899)\n",
      "NaiveBayesBernoulli: roc_auc (0.826842), std (0.020672)\n",
      "NaiveBayesMultinomial: roc_auc (0.827583), std (0.020732)\n",
      "RandomForest: roc_auc (0.767739), std (0.019510)\n",
      "ExtraTrees: roc_auc (0.783671), std (0.020281)\n",
      "\n",
      " Model with best roc_auc is NaiveBayesMultinomial\n",
      "\n",
      " MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n"
     ]
    }
   ],
   "source": [
    "best_clf = find_best_classifier(features=features, \n",
    "                                target=y, \n",
    "                                seed=42, \n",
    "                                k_folds=5, \n",
    "                                crossval_scoring='roc_auc',\n",
    "                                models_list = models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test models with W2V Mean Embedding Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = generate_features(MeanEmbeddingVectorizer(w2v), tokenized_test, set_dim=100)\n",
    "\n",
    "models = [('RandomForest', RandomForestClassifier(random_state=seed)),\n",
    "          ('ExtraTrees', ExtraTreesClassifier(random_state=seed))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest: roc_auc (0.669129), std (0.032995)\n",
      "ExtraTrees: roc_auc (0.666367), std (0.029718)\n",
      "\n",
      " Model with best roc_auc is RandomForest\n",
      "\n",
      " RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "best_clf = find_best_classifier(features=features, \n",
    "                                target=y, \n",
    "                                seed=42, \n",
    "                                k_folds=5, \n",
    "                                crossval_scoring='roc_auc',\n",
    "                                models_list = models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test models with W2V Tf-IDF Embedding Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = generate_features(TfidfEmbeddingVectorizer(w2v), tokenized_test, set_dim=100)\n",
    "\n",
    "models = [('RandomForest', RandomForestClassifier(random_state=seed)),\n",
    "          ('ExtraTrees', ExtraTreesClassifier(random_state=seed))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest: roc_auc (0.669129), std (0.032995)\n",
      "ExtraTrees: roc_auc (0.666367), std (0.029718)\n",
      "\n",
      " Model with best roc_auc is RandomForest\n",
      "\n",
      " RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "best_clf = find_best_classifier(features=features, \n",
    "                                target=y, \n",
    "                                seed=42, \n",
    "                                k_folds=5, \n",
    "                                crossval_scoring='roc_auc',\n",
    "                                models_list = models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
